import re
import time

import json


def read_test_data():
    data_list = []
    with open('data/test.jsonl', 'r') as f:
        data = f.readlines()
        for line in data:
            line = json.loads(line)
            data_list.append(line)
    return data_list


class Evaluation:
    """
    Base evaluation class, evaluate the baseline of zero-shot and few-shot
    """

    def __init__(self, llm, record_path, num_of_shots=0):
        self.data_list = read_test_data()
        self.llm = llm
        # zero-shot or few-shot
        self.num_of_shots = num_of_shots
        # the file path to record the evaluation result
        self.record_path = record_path

    def generate_prompt(self, question):
        return question

    def evaluation(self, data):
        """
        compare the result from llm with the correct answer
        record the evaluation result in a jsonl file
        """
        # generate prompt
        prompt = self.generate_prompt(data['question'])
        # call llm
        full_response = self.llm.get_full_response(prompt)
        # convert the answer into numerical form
        answer = self.convert_answer(data['answer'])
        llm_answer = self.convert_answer(full_response['answer'])
        print('question', data['question'])
        print('llm response', full_response['answer'])
        print('answer vs llm_answer', answer, llm_answer)
        self.record_evaluation(data['question'], answer, llm_answer, [data['answer']],
                               full_response['completion_tokens'],
                               full_response['time'])
        return llm_answer == answer

    def record_evaluation(self, question, answer, llm_answer, generated, completion_tokens, time):
        """
        record the evaluation result in a jsonl file

        Args:
            question: question to be asked
            answer: correct answer
            llm_answer: model-predicted answer
            generated: content generated by the model, type: list
            completion_tokens: number of tokens used in the output
            time: time used for the generation
        """
        with open(self.record_path, 'a') as f:
            record = {
                'question': question,
                'answer': answer,
                'llm_answer': llm_answer,
                'generated': generated,
                'completion_tokens': completion_tokens,
                'time': time
            }
            f.write(json.dumps(record) + '\n')

    def run_evaluation(self):
        total_cnt = len(self.data_list)
        correct_cnt = 0
        start_index = 0
        while True:
            try:
                for i in range(start_index, total_cnt):
                    print('No.', start_index + 1, sep='')
                    result = self.evaluation(self.data_list[i])
                    start_index += 1
                    if result:
                        correct_cnt += 1
                    print('correct_rate', correct_cnt / start_index)
                    if start_index % 10 == 0:
                        time.sleep(10)
                break
            except Exception as e:
                print('abort', e)
                # rate_limit_exceed, sleep for 10s
                time.sleep(10)
        print('total correct_rate', correct_cnt / total_cnt)

    def convert_answer(self, answer):
        answer = self.extract_ans_from_response(answer)
        if not self.is_number(answer):
            answer = re.findall('-?\d+(?:\.\d+)?(?:/\d+)?', answer)[0]
        answer = self.delete_extra_zero(answer)
        return answer

    def is_number(self, s):
        try:
            float(s)
            return True
        except ValueError:
            pass
        try:
            import unicodedata
            unicodedata.numeric(s)
            return True
        except (TypeError, ValueError):
            pass
        return False

    def delete_extra_zero(self, n):
        """Delete the extra 0 after the decimal point"""
        try:
            n = float(n)
        except:
            # print("None {}".format(n))
            return n
        if isinstance(n, int):
            return str(n)
        if isinstance(n, float):
            n = str(n).rstrip('0')  # 删除小数点后多余的0
            n = int(n.rstrip('.')) if n.endswith('.') else float(n)  # 只剩小数点直接转int，否则转回float
            n = str(n)
            return n

    def extract_ans_from_response(self, answer: str, eos=None):
        """
        :param answer: model-predicted solution or golden answer string
        :param eos: stop token
        :return:
        """
        if eos:
            answer = answer.split(eos)[0].strip()

        answer = answer.split('####')[-1].strip()

        for remove_char in [',', '$', '%', 'g']:
            answer = answer.replace(remove_char, '')

        try:
            return int(answer)
        except ValueError:
            return answer

# if __name__ == '__main__':
#     # test_solution = "Anna has 2 more apples than Elsa. So Anna has 2 + 5 = 7 apples. Elsa and Anna have 5 + 7 = 12 apples together. #### 12 apples"
#     # answer = extract_ans_from_response(test_solution)
#     # answer = re.findall('-?\d+(?:\.\d+)?(?:/\d+)?', answer)[0]
#     # answer = delete_extra_zero(answer)
#     # print(answer)
